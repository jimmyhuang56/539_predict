#strategy_combiner.py
import pandas as pd
from xgboost import XGBClassifier

FEATURE_CSV = "features.csv"
TOP_N = 10
CONDITION_PARAMS = {
    "cooldown": 15,
    "momentum": -1,
    "score": 1.5
}

# ğŸ“¦ è¼‰å…¥è³‡æ–™
df = pd.read_csv(FEATURE_CSV)
latest_date = df["date"].max()
latest_df = df[df["date"] == latest_date].copy()

# ğŸ§  æ‰‹å‹•åŠ æ¬Šåˆ†æ•¸ï¼ˆTop-Nï¼‰
latest_df["score"] = (
    1.2 * latest_df["is_hot_tail"] +
    1.0 * latest_df["is_recent_hot"] +
    0.8 * latest_df["momentum"] +
    0.6 * latest_df["draw_streak"] +
    0.5 * latest_df["freq_20"] +
    0.3 * latest_df["tail_freq_10"] -
    0.2 * latest_df["cooldown"]
)
topn_selected = latest_df.sort_values(by="score", ascending=False).head(TOP_N)

# ğŸ“Š æ¢ä»¶é¸è™Ÿ
condition_selected = latest_df[
    (latest_df["is_hot_tail"] == 1) &
    (latest_df["momentum"] >= CONDITION_PARAMS["momentum"]) &
    (latest_df["cooldown"] < CONDITION_PARAMS["cooldown"]) &
    (latest_df["score"] >= CONDITION_PARAMS["score"])
]

# ğŸ”® æ¨¡å‹é æ¸¬æ©Ÿç‡é¸è™Ÿ
X = df.drop(columns=["date", "number", "is_drawn"])
y = df["is_drawn"]
model = XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    scale_pos_weight=6,
    eval_metric="logloss",
    random_state=42
)
model.fit(X, y)
X_latest = latest_df.drop(columns=["date", "number", "is_drawn", "score"])
latest_df.loc[:, "prob"] = model.predict_proba(X_latest)[:, 1]
model_selected = latest_df.sort_values(by="prob", ascending=False).head(TOP_N)

# ğŸ“ˆ æ¨¡å‹åŠ æ¬Šåˆ†æ•¸ï¼ˆgain_scoreï¼‰
gain_dict = model.get_booster().get_score(importance_type='gain')
def compute_gain_score(row):
    return sum(gain_dict.get(f, 0) * row[f] for f in gain_dict if f in row)
latest_df["gain_score"] = latest_df.apply(compute_gain_score, axis=1)
gain_selected = latest_df.sort_values(by="gain_score", ascending=False).head(TOP_N)
# ğŸ”— èåˆé¸è™Ÿï¼ˆèåˆåˆ†æ•¸ï¼‰
latest_df["fusion_score"] = (
    0.4 * latest_df["score"] +
    0.3 * latest_df["prob"] +
    0.3 * latest_df["gain_score"]
)

fusion_selected = latest_df.sort_values(by="fusion_score", ascending=False).head(TOP_N)

#è‡ªå‹•ç”Ÿæˆç­–ç•¥åˆ†æ•¸å…¬å¼
def extract_gain_weights(model, normalize=True):
    gain_dict = model.get_booster().get_score(importance_type='gain')
    if normalize:
        total = sum(gain_dict.values())
        gain_dict = {k: v / total for k, v in gain_dict.items()}
    return gain_dict

def compute_strategy_score(df, weights, score_col="auto_score"):
    df[score_col] = df.apply(
        lambda row: sum(weights.get(f, 0) * row.get(f, 0) for f in weights),
        axis=1
    )
    return df

def generate_strategy_score(model, latest_df, normalize=True, score_col="auto_score"):
    weights = extract_gain_weights(model, normalize=normalize)
    latest_df = compute_strategy_score(latest_df, weights, score_col=score_col)
    return latest_df, weights

# è‡ªå‹•ç”Ÿæˆç­–ç•¥åˆ†æ•¸
latest_df, gain_weights = generate_strategy_score(model, latest_df)

# èåˆæ¨¡å‹æ©Ÿç‡èˆ‡ç­–ç•¥åˆ†æ•¸
latest_df["fusion_score"] = (
    0.5 * latest_df["auto_score"] +
    0.5 * latest_df["prob"]
)

# ç²¾é¸ Top-N è™Ÿç¢¼ï¼ˆä¾ fusion_scoreï¼‰
fusion_selected = latest_df.sort_values(by="fusion_score", ascending=False).head(TOP_N)

# ğŸ”— çµ±æ•´é¸è™Ÿ
def extract_numbers(df): return set(df["number"].tolist())
sets = {
    "Top-N": extract_numbers(topn_selected),
    "æ¢ä»¶é¸è™Ÿ": extract_numbers(condition_selected),
    "æ¨¡å‹æ©Ÿç‡": extract_numbers(model_selected),
    "æ¨¡å‹åŠ æ¬Š": extract_numbers(gain_selected),
    "èåˆé¸è™Ÿ": extract_numbers(fusion_selected)

}

# ğŸ§¾ è¼¸å‡ºç¶œåˆé¸è™Ÿçµæœ
print("\nğŸ¯ ç¶œåˆé¸è™Ÿçµæœï¼ˆå¤šç­–ç•¥èåˆï¼‰ï¼š")
all_numbers = sorted(set.union(*sets.values()))
for num in all_numbers:
    sources = [name for name, s in sets.items() if num in s]
    print(f"è™Ÿç¢¼ {num:>2} â† ä¾†è‡ªï¼š{', '.join(sources)}")

# ğŸ“Š é¡å¤–çµ±è¨ˆ
print("\nğŸ“Š ç­–ç•¥é‡ç–Šçµ±è¨ˆï¼š")
for name, s in sets.items():
    print(f"{name:<8} â†’ é¸å‡º {len(s)} å€‹è™Ÿç¢¼")
print(f"ç¸½ç¶œåˆé¸è™Ÿæ•¸ï¼š{len(all_numbers)}")

latest_df.to_csv("latest_processed_df.csv", index=False)