import pandas as pd
from xgboost import XGBClassifier

FEATURE_CSV = "features.csv"
TARGET_COLUMN = "is_drawn"

# ðŸ“¦ è¼‰å…¥è³‡æ–™
df = pd.read_csv(FEATURE_CSV)
latest_date = df["date"].max()
latest_df = df[df["date"] == latest_date].copy()

# ðŸ§ª æº–å‚™è¨“ç·´è³‡æ–™
X = df.drop(columns=["date", "number", TARGET_COLUMN])
y = df[TARGET_COLUMN]

# ðŸ§  è¨“ç·´æ¨¡åž‹
model = XGBClassifier(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    scale_pos_weight=6,
    eval_metric="logloss",
    random_state=42
)
model.fit(X, y)

# ðŸ“Š å–å¾— gain ä½œç‚ºåŠ æ¬Šä¿‚æ•¸
gain_dict = model.get_booster().get_score(importance_type='gain')

# ðŸ”§ è¨ˆç®—æ¯å€‹è™Ÿç¢¼çš„åŠ æ¬Šåˆ†æ•¸
def compute_score(row):
    score = 0
    for feature, gain in gain_dict.items():
        if feature in row:
            score += gain * row[feature]
    return score

latest_df["gain_score"] = latest_df.apply(compute_score, axis=1)

# ðŸ” é¸å‡ºåˆ†æ•¸æœ€é«˜çš„å‰ N å€‹è™Ÿç¢¼
selected = latest_df.sort_values(by="gain_score", ascending=False).head(10)

# ðŸ“Š é¡¯ç¤ºçµæžœ
print("\nðŸ“ˆ æ¨¡åž‹åŠ æ¬Šåˆ†æ•¸é¸è™Ÿçµæžœï¼ˆä¾ gain_score æŽ’åºï¼‰ï¼š")
for _, row in selected.iterrows():
    print(f"è™Ÿç¢¼ {row['number']:>2} â†’ åˆ†æ•¸ {row['gain_score']:.4f}")